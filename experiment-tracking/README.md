# ğŸš– MLflow Experiment Tracking â€“ Chicago Taxi Duration Prediction

This project builds an end-to-end experiment tracking workflow using **MLflow**, focusing on training and comparing machine learning models to predict taxi trip duration using the Chicago Taxi dataset.

---

## ğŸ“ Folder Structure
```
experiment-tracking/
â”œâ”€â”€ experiment-tracking.ipynb # Main notebook containing training, evaluation, and model registry logic
â”œâ”€â”€ mlflow.db # SQLite database for MLflow tracking
â”œâ”€â”€ mlruns/ # MLflow run metadata (autogenerated)
â”œâ”€â”€ models/ # Directory to store preprocessor and trained model artifacts
â””â”€â”€ mlartifacts/ # Optional MLflow artifact logging output
```

---
## ğŸš€ Project Overview

This notebook performs the following:

- ğŸ“¦ Loads and preprocesses the Chicago taxi dataset
- ğŸ§¹ Performs feature engineering (speed, fare per mile, time features)
- ğŸ“Š Trains multiple models (XGBoost, Random Forest, SVR, etc.)
- ğŸ” Logs hyperparameter tuning trials using Hyperopt
- ğŸ§ª Evaluates models using RMSE
- ğŸ“ Logs metrics, parameters, and artifacts to MLflow
- ğŸ·ï¸ Tags runs with developer and model type
- ğŸ Registers the best model and transitions it to Production stage

---

## âš™ï¸ Technologies & Libraries Used

- Python, Pandas, Scikit-learn, XGBoost, Hyperopt
- **MLflow** (for experiment tracking and model registry)
- SQLite (as backend MLflow store)
- Pickle (for saving preprocessor objects)

---

## ğŸ”¬ Models Tracked

- `XGBoostRegressor`
- `RandomForestRegressor`
- `GradientBoostingRegressor`
- `ExtraTreesRegressor`
- `LinearSVR`

All models are evaluated and logged using consistent metrics and preprocessed features.

---

## ğŸ“¦ Example MLflow Logging

Each MLflow run logs:

- Model name and parameters (e.g., `max_depth`, `n_estimators`)
- RMSE score on validation data
- Feature preprocessing metadata as artifacts
- Trained models using `mlflow.sklearn` or `mlflow.xgboost`

---

## ğŸ·ï¸ Model Registry

The best model is:

- Registered under the name: `chicago-taxi-experiment`
- Transitioned to the `"Production"` stage using `MlflowClient`
- Annotated with a description and timestamp

## ğŸ§ª Querying Experiments

MLflow client functions are used to:

- List all experiments
- Filter top runs with `rmse < 5`
- Load run details and register models programmatically

---
## ğŸ§° How to Run

### 1. Install dependencies
Make sure you have Python 3.x and the required packages installed. You can install dependencies using:
```bash
pipenv shell 
pipenv lock
```

### 2.Start the MLflow UI
```bash
mlflow ui --backend-store-uri sqlite:///mlflow.db
```

### 3. Run the notebook
Launch ```experiment-tracking.ipynb``` in Jupyter and execute all cells.

### 4. Downloading the Production Model

Once the best model is promoted to the **Production** stage using MLflow, we retrieve both the trained model and its associated preprocessor from the MLflow artifacts.

The model (e.g., a RandomForest or XGBoost regressor) is downloaded into the `models/rf_model/` directory. The preprocessing object, which includes feature names or transformation logic, is also downloaded and saved as `models/preprocessor.b`.

This allows us to load the exact version of the model and preprocessing steps later for inference or deployment, ensuring consistency and reproducibility.


## ğŸ‘¤ Author
Developed by Dario Dang

