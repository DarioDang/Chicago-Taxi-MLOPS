# 🚖 MLflow Experiment Tracking – Chicago Taxi Duration Prediction

This project builds an end-to-end experiment tracking workflow using **MLflow**, focusing on training and comparing machine learning models to predict taxi trip duration using the Chicago Taxi dataset.

---

## 📁 Folder Structure
```
experiment-tracking/
├── experiment-tracking.ipynb # Main notebook containing training, evaluation, and model registry logic
├── mlflow.db # SQLite database for MLflow tracking
├── mlruns/ # MLflow run metadata (autogenerated)
├── models/ # Directory to store preprocessor and trained model artifacts
└── mlartifacts/ # Optional MLflow artifact logging output
```

---
## 🚀 Project Overview

This notebook performs the following:

- 📦 Loads and preprocesses the Chicago taxi dataset
- 🧹 Performs feature engineering (speed, fare per mile, time features)
- 📊 Trains multiple models (XGBoost, Random Forest, SVR, etc.)
- 🔁 Logs hyperparameter tuning trials using Hyperopt
- 🧪 Evaluates models using RMSE
- 📝 Logs metrics, parameters, and artifacts to MLflow
- 🏷️ Tags runs with developer and model type
- 🏁 Registers the best model and transitions it to Production stage

---

## ⚙️ Technologies & Libraries Used

- Python, Pandas, Scikit-learn, XGBoost, Hyperopt
- **MLflow** (for experiment tracking and model registry)
- SQLite (as backend MLflow store)
- Pickle (for saving preprocessor objects)

---

## 🔬 Models Tracked

- `XGBoostRegressor`
- `RandomForestRegressor`
- `GradientBoostingRegressor`
- `ExtraTreesRegressor`
- `LinearSVR`

All models are evaluated and logged using consistent metrics and preprocessed features.

---

## 📦 Example MLflow Logging

Each MLflow run logs:

- Model name and parameters (e.g., `max_depth`, `n_estimators`)
- RMSE score on validation data
- Feature preprocessing metadata as artifacts
- Trained models using `mlflow.sklearn` or `mlflow.xgboost`

---

## 🏷️ Model Registry

The best model is:

- Registered under the name: `chicago-taxi-experiment`
- Transitioned to the `"Production"` stage using `MlflowClient`
- Annotated with a description and timestamp

## 🧪 Querying Experiments

MLflow client functions are used to:

- List all experiments
- Filter top runs with `rmse < 5`
- Load run details and register models programmatically

---
## 🧰 How to Run

### 1. Install dependencies
Make sure you have Python 3.x and the required packages installed. You can install dependencies using:
```bash
pipenv shell 
pipenv lock
```

### 2.Start the MLflow UI
```bash
mlflow ui --backend-store-uri sqlite:///mlflow.db
```

### 3. Run the notebook
Launch ```experiment-tracking.ipynb``` in Jupyter and execute all cells.

### 4. Downloading the Production Model

Once the best model is promoted to the **Production** stage using MLflow, we retrieve both the trained model and its associated preprocessor from the MLflow artifacts.

The model (e.g., a RandomForest or XGBoost regressor) is downloaded into the `models/rf_model/` directory. The preprocessing object, which includes feature names or transformation logic, is also downloaded and saved as `models/preprocessor.b`.

This allows us to load the exact version of the model and preprocessing steps later for inference or deployment, ensuring consistency and reproducibility.


## 👤 Author
Developed by Dario Dang

