# Chicago Taxi MLOps Best Practice
A production-ready machine learning workflow for predicting taxi trip durations using the Chicago Taxi dataset. The application includes data preprocessing, model loading from MLflow (hosted in S3), a Flask API for prediction, and comprehensive testing.

---

## ğŸš€ Features

- ğŸ” Reproducible environment with `pipenv`
- ğŸ§ª Unit and integration tests with `pytest`
- ğŸ§¼ Code linting with `pylint` or `ruff`
- ğŸ§¹ Auto-formatting with `black`
- ğŸ›  Task automation via `Makefile`
- âš™ï¸ ML model and preprocessing artifacts loaded from S3 using MLflow


## ğŸ“ Project Structure
```bash
Best-Practices/
â”œâ”€â”€ Code/
â”‚ â”œâ”€â”€ aws_predict.py # Main Flask app and prediction logic
â”‚ â”œâ”€â”€ init.py
â”‚ â””â”€â”€ tests/
â”‚ â”œâ”€â”€ unit/ # Unit tests for feature functions
â”‚ â”‚ â””â”€â”€ test_unit.py
â”‚ â””â”€â”€ integration/ # Integration tests for API
â”‚ â””â”€â”€ test_integration.py
â”œâ”€â”€ Pipfile / Pipfile.lock # Dependency management via Pipenv
â”œâ”€â”€ Makefile # Dev commands for test, lint, run, etc.
â”œâ”€â”€ README.md
```

## ğŸ§ª Running Tests

ğŸ§° Setup Instructions

1. Install Pipenv

2. Install dependencies:
```bash
make install
```

3. From project root (Best-Practices/), run:

| Command                 | What it does                                 |
| ----------------------- | -------------------------------------------- |
| `make install`          | Install all dev dependencies via Pipenv      |
| `make format`           | Auto-format code using Black                 |
| `make lint`             | Lint your code using Ruff                    |
| `make unit-test`        | Run only unit tests                          |
| `make integration-test` | Run only integration tests                   |
| `make test`             | Run all tests                                |
| `make run`              | Start the Flask app in development mode      |
| `make clean`            | Remove caches, compiled files, and temp data |


## ğŸ‘¤ Author

Dario Dang

ML Engineer | MLOps Enthusiast | DataOps Practitioner
